#!/usr/bin/env python3
"""
Script d'analyse des rÃ©sultats d'expÃ©rience
"""

import sqlite3
import pandas as pd
import json
from datetime import datetime

def load_experiment_data():
    """Charge les donnÃ©es de l'expÃ©rience depuis la base SQLite"""
    db_path = "experiment_results/experiment_data.db"
    
    try:
        conn = sqlite3.connect(db_path)
        
        # RÃ©cupÃ©rer toutes les donnÃ©es
        query = """
        SELECT 
            query_id,
            query_text,
            model_name,
            response_raw as response_text,
            sources_extracted as sources_json,
            response_time_ms,
            timestamp,
            session_id,
            iteration,
            query_category
        FROM results 
        ORDER BY timestamp DESC
        """
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        print(f"ğŸ“Š {len(df)} enregistrements chargÃ©s depuis la base de donnÃ©es")
        return df
        
    except Exception as e:
        print(f"âŒ Erreur lors du chargement: {e}")
        return None

def analyze_sources(df):
    """Analyse les sources citÃ©es par chaque modÃ¨le"""
    print("\nğŸ” ANALYSE DES SOURCES PAR MODÃˆLE")
    print("=" * 60)
    
    source_stats = {}
    
    for _, row in df.iterrows():
        model = row['model_name']
        if model not in source_stats:
            source_stats[model] = {'with_sources': 0, 'total': 0, 'total_sources': 0}
        
        source_stats[model]['total'] += 1
        
        # Parser les sources JSON
        try:
            sources = json.loads(row['sources_json']) if row['sources_json'] else []
            if sources:
                source_stats[model]['with_sources'] += 1
                source_stats[model]['total_sources'] += len(sources)
        except:
            pass
    
    # Afficher les statistiques
    for model, stats in source_stats.items():
        pct_with_sources = (stats['with_sources'] / stats['total']) * 100 if stats['total'] > 0 else 0
        avg_sources = stats['total_sources'] / stats['with_sources'] if stats['with_sources'] > 0 else 0
        
        print(f"\nğŸ“‹ {model}:")
        print(f"  â€¢ RÃ©ponses avec sources: {stats['with_sources']}/{stats['total']} ({pct_with_sources:.1f}%)")
        print(f"  â€¢ Sources moyennes par rÃ©ponse: {avg_sources:.1f}")
        print(f"  â€¢ Total sources uniques: {stats['total_sources']}")

def analyze_response_quality(df):
    """Analyse la qualitÃ© et longueur des rÃ©ponses"""
    print("\nğŸ“ ANALYSE DE LA QUALITÃ‰ DES RÃ‰PONSES")
    print("=" * 60)
    
    response_stats = df.groupby('model_name').agg({
        'response_text': ['count', lambda x: x.str.len().mean(), lambda x: x.str.len().std()],
        'response_time_ms': ['mean', 'std']
    }).round(2)
    
    response_stats.columns = ['Nb_RÃ©ponses', 'Long_Moyenne', 'Ã‰cart_Type_Long', 'Temps_Moyen_ms', 'Ã‰cart_Type_Temps']
    
    print(response_stats)

def analyze_by_query_type(df):
    """Analyse les rÃ©sultats par type de requÃªte"""
    print("\nğŸ¯ ANALYSE PAR TYPE DE REQUÃŠTE")
    print("=" * 60)
    
    # Mapper les query_id aux catÃ©gories
    query_categories = {
        'info_sante_001': 'Informationnelle - SantÃ©',
        'info_tech_001': 'Informationnelle - Technique', 
        'transac_voyage_001': 'Transactionnelle - Voyage'
    }
    
    for query_id, category in query_categories.items():
        query_data = df[df['query_id'] == query_id]
        if len(query_data) > 0:
            print(f"\nğŸ” {category} ({query_id}):")
            print(f"  â€¢ Total rÃ©ponses: {len(query_data)}")
            
            # Analyser par modÃ¨le
            for model in query_data['model_name'].unique():
                model_data = query_data[query_data['model_name'] == model]
                avg_length = model_data['response_text'].str.len().mean()
                
                # Compter les sources
                sources_count = 0
                for _, row in model_data.iterrows():
                    try:
                        sources = json.loads(row['sources_json']) if row['sources_json'] else []
                        sources_count += len(sources)
                    except:
                        pass
                
                print(f"    - {model}: {len(model_data)} rÃ©ponses, {avg_length:.0f} chars moy., {sources_count} sources")

def show_sample_responses(df):
    """Affiche des Ã©chantillons de rÃ©ponses"""
    print("\nğŸ“„ Ã‰CHANTILLONS DE RÃ‰PONSES DÃ‰TAILLÃ‰ES")
    print("=" * 80)
    
    # Prendre un Ã©chantillon de chaque modÃ¨le
    for model in df['model_name'].unique():
        model_data = df[df['model_name'] == model].head(1)
        
        for _, row in model_data.iterrows():
            print(f"\nğŸ¤– MODÃˆLE: {row['model_name']}")
            print(f"â“ REQUÃŠTE: {row['query_text'][:60]}...")
            print(f"â±ï¸  TEMPS: {row['response_time_ms']}ms")
            print(f"ğŸ’¬ RÃ‰PONSE ({len(row['response_text'])} chars):")
            print(f"   {row['response_text'][:200]}...")
            
            try:
                sources = json.loads(row['sources_json']) if row['sources_json'] else []
                if sources:
                    print(f"ğŸ“š SOURCES ({len(sources)}):")
                    for i, source in enumerate(sources[:3], 1):
                        title = source.get('title', 'Sans titre')[:50]
                        url = source.get('url', 'Sans URL')[:50]
                        print(f"   {i}. {title} - {url}")
                else:
                    print("ğŸ“š SOURCES: Aucune")
            except:
                print("ğŸ“š SOURCES: Erreur de parsing")
            
            print("-" * 80)

def main():
    """Fonction principale d'analyse"""
    print("ğŸ”¬ ANALYSE DES RÃ‰SULTATS D'EXPÃ‰RIENCE")
    print("=" * 80)
    
    df = load_experiment_data()
    if df is None:
        return
    
    print(f"ğŸ“… PÃ©riode analysÃ©e: {df['timestamp'].min()} Ã  {df['timestamp'].max()}")
    print(f"ğŸ”„ Sessions: {df['session_id'].nunique()}")
    print(f"â“ RequÃªtes uniques: {df['query_id'].nunique()}")
    print(f"ğŸ¤– ModÃ¨les testÃ©s: {', '.join(df['model_name'].unique())}")
    
    analyze_sources(df)
    analyze_response_quality(df)
    analyze_by_query_type(df)
    show_sample_responses(df)

if __name__ == "__main__":
    main()