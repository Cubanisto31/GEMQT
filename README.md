# Framework d'ExpÃ©rimentation sur le RÃ©fÃ©rencement des Sources

Ce projet fournit un framework complet pour mener des expÃ©rimentations Ã  grande Ã©chelle sur la maniÃ¨re dont les modÃ¨les de langage (LLMs) et les moteurs de recherche citent leurs sources. Il est conÃ§u pour Ãªtre modulaire, extensible et automatisÃ©.

## NouveautÃ©s ğŸ‰

### âœ… Support des fichiers de requÃªtes externes
Les requÃªtes peuvent maintenant Ãªtre chargÃ©es depuis un fichier Excel ou CSV externe, Ã©vitant de modifier le fichier de configuration YAML.

### âœ… RÃ©ponses complÃ¨tes sauvegardÃ©es
Les rÃ©ponses complÃ¨tes sont dÃ©sormais sauvegardÃ©es dans le champ `response_raw` de la base de donnÃ©es.

### âœ… Nouveaux modÃ¨les et moteurs ajoutÃ©s
- **Bing Search API** - Moteur de recherche Microsoft
- **Google Gemini** - LLM de Google
- **Perplexity AI** - LLM avec recherche web intÃ©grÃ©e
- **Claude** (dÃ©jÃ  implÃ©mentÃ©)

### ğŸ“– Guide d'obtention des clÃ©s API
Consultez [API_SETUP_GUIDE.md](API_SETUP_GUIDE.md) pour des instructions dÃ©taillÃ©es sur l'obtention des clÃ©s API.

## Structure du Projet

```
.
â”œâ”€â”€ ğŸ“‚ experiment_results/
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ clients/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_client.py
â”‚   â”‚   â”œâ”€â”€ claude_client.py
â”‚   â”‚   â”œâ”€â”€ openai_client.py
â”‚   â”‚   â”œâ”€â”€ gemini_client.py
â”‚   â”‚   â”œâ”€â”€ perplexity_client.py
â”‚   â”‚   â””â”€â”€ search_clients.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ config.yaml
â”‚   â”œâ”€â”€ config_without_queries.yaml  # Config sans requÃªtes intÃ©grÃ©es
â”‚   â”œâ”€â”€ query_loader.py             # Chargement des requÃªtes externes
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ runner.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ API_SETUP_GUIDE.md
â”œâ”€â”€ CLAUDE.md
â”œâ”€â”€ queries_pool_v1.xlsx           # Pool de requÃªtes Excel existant
â”œâ”€â”€ queries_pool_example.csv       # Exemple de fichier CSV
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Configuration

### 1. Installation des dÃ©pendances
```bash
pip install -r requirements.txt
```

### 2. Configuration des clÃ©s API
CrÃ©ez un fichier `.env` Ã  la racine du projet :
```env
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
BING_API_KEY=...
GEMINI_API_KEY=...
PERPLEXITY_API_KEY=...
GOOGLE_API_KEY=...
GOOGLE_CX=...
```

### 3. Activation des modÃ¨les
Dans `src/config.yaml`, changez `enabled: false` en `enabled: true` pour les modÃ¨les que vous souhaitez utiliser.

## Utilisation

### ExÃ©cution simple
```bash
python -m src.main
```

### Avec configuration personnalisÃ©e
```bash
python -m src.main --config mon_config.yaml
```

### Avec fichier de requÃªtes externe
Le systÃ¨me supporte maintenant le chargement des requÃªtes depuis un fichier externe (Excel ou CSV) :

```bash
# Avec un fichier Excel
python -m src.main --queries queries_pool_v1.xlsx

# Avec un fichier CSV
python -m src.main --queries queries_pool_example.csv

# Avec une configuration personnalisÃ©e ET un fichier de requÃªtes externe
python -m src.main --config src/config_without_queries.yaml --queries queries_pool_v1.xlsx
```

#### Format du fichier de requÃªtes

Le fichier Excel ou CSV doit contenir au minimum les colonnes suivantes :
- **id** : Identifiant unique de la requÃªte
- **text** : Texte de la requÃªte
- **category** : CatÃ©gorie de la requÃªte (ex: "Informationnelle - SantÃ©", "Transactionnelle - Voyage", etc.)

Les colonnes supplÃ©mentaires seront automatiquement ajoutÃ©es comme mÃ©tadonnÃ©es. Exemple de fichier CSV :

```csv
id,text,category,complexitÃ©,domaine,intention
info_sante_001,"Quels sont les symptÃ´mes de la grippe ?","Informationnelle - SantÃ©",faible,santÃ©,
info_tech_001,"Explique le fonctionnement des transformeurs dans GPT.","Informationnelle - Technique",Ã©levÃ©e,technologie,
transac_voyage_001,"Trouver les meilleurs hÃ´tels Ã  Rome.","Transactionnelle - Voyage",,tourisme,rÃ©servation
```

## Base de donnÃ©es et stockage des rÃ©sultats

### Configuration du fichier de sortie

Le fichier de base de donnÃ©es est configurÃ© dans le fichier `config.yaml` via le paramÃ¨tre `database_url` :

```yaml
database_url: "sqlite:///experiment_results/experiment_data.db"
```

Vous pouvez modifier ce chemin pour :
- Changer l'emplacement de la base de donnÃ©es
- Utiliser une base de donnÃ©es diffÃ©rente pour chaque expÃ©rimentation
- Utiliser d'autres systÃ¨mes de base de donnÃ©es supportÃ©s par SQLAlchemy (PostgreSQL, MySQL, etc.)

Exemple avec PostgreSQL :
```yaml
database_url: "postgresql://user:password@localhost/experiment_db"
```

### Structure de la base de donnÃ©es

La base de donnÃ©es SQLite contient une table `results` avec la structure suivante :

| Champ | Type | Description |
|-------|------|-------------|
| **id** | String (PK) | Identifiant unique de chaque rÃ©sultat |
| **experiment_id** | String | Nom de l'expÃ©rimentation (depuis config.yaml) |
| **session_id** | String | UUID unique de la session d'exÃ©cution |
| **query_id** | String | Identifiant de la requÃªte |
| **query_text** | Text | Texte complet de la requÃªte |
| **query_category** | String | CatÃ©gorie de la requÃªte |
| **iteration** | Integer | NumÃ©ro de l'itÃ©ration (pour les rÃ©pÃ©titions) |
| **model_name** | String | Nom du modÃ¨le/moteur utilisÃ© |
| **model_type** | String | Type (llm ou search_engine) |
| **response_raw** | Text | **RÃ©ponse complÃ¨te** du modÃ¨le/moteur |
| **sources_extracted** | JSON | Sources citÃ©es extraites de la rÃ©ponse |
| **chain_of_thought** | Text | Raisonnement extrait (si applicable) |
| **response_time_ms** | Integer | Temps de rÃ©ponse en millisecondes |
| **timestamp** | DateTime | Date et heure de l'exÃ©cution |
| **extra_metadata** | JSON | MÃ©tadonnÃ©es supplÃ©mentaires |

### Manipulation des donnÃ©es

#### AccÃ¨s direct avec SQLite

```bash
# Ouvrir la base de donnÃ©es
sqlite3 experiment_results/experiment_data.db

# Commandes SQL utiles
.tables                          # Lister les tables
.schema results                  # Voir la structure de la table
SELECT COUNT(*) FROM results;   # Compter les rÃ©sultats
.mode column                     # Affichage en colonnes
.headers on                      # Afficher les en-tÃªtes
```

#### RequÃªtes SQL exemples

```sql
-- Voir les derniers rÃ©sultats
SELECT model_name, query_id, response_time_ms, timestamp 
FROM results 
ORDER BY timestamp DESC 
LIMIT 10;

-- Statistiques par modÃ¨le
SELECT model_name, 
       COUNT(*) as nb_requetes,
       AVG(response_time_ms) as temps_moyen_ms,
       COUNT(DISTINCT query_id) as nb_requetes_uniques
FROM results 
GROUP BY model_name;

-- Exporter les rÃ©ponses complÃ¨tes pour une requÃªte
SELECT model_name, response_raw 
FROM results 
WHERE query_id = 'info_sante_001';

-- Compter les sources par modÃ¨le
SELECT model_name, 
       AVG(json_array_length(sources_extracted)) as nb_moyen_sources
FROM results 
GROUP BY model_name;
```

#### AccÃ¨s avec Python

```python
import sqlite3
import pandas as pd
import json

# Connexion Ã  la base
conn = sqlite3.connect('experiment_results/experiment_data.db')

# Charger les donnÃ©es dans un DataFrame
df = pd.read_sql_query("SELECT * FROM results", conn)

# Analyser les rÃ©ponses
for index, row in df.iterrows():
    print(f"ModÃ¨le: {row['model_name']}")
    print(f"RequÃªte: {row['query_text'][:50]}...")
    print(f"Longueur rÃ©ponse: {len(row['response_raw'])} caractÃ¨res")
    
    # Analyser les sources
    sources = json.loads(row['sources_extracted']) if row['sources_extracted'] else []
    print(f"Nombre de sources: {len(sources)}")
    print("-" * 50)

# Exporter vers CSV
df.to_csv('resultats_experimentation.csv', index=False)

conn.close()
```

#### Scripts d'analyse fournis

Le projet inclut plusieurs scripts pour analyser les donnÃ©es :

- **`export_to_csv.py`** : Exporte les donnÃ©es vers CSV avec agrÃ©gations
- **`analyze_experiment.py`** : GÃ©nÃ¨re des statistiques et graphiques
- **`quick_data_peek.py`** : AperÃ§u rapide des derniers rÃ©sultats

Utilisation :
```bash
# Exporter vers CSV
python export_to_csv.py

# Analyser et crÃ©er des graphiques
python analyze_experiment.py

# AperÃ§u rapide
python quick_data_peek.py
```

### Sauvegarde et archivage

Il est recommandÃ© de :
1. **Sauvegarder rÃ©guliÃ¨rement** la base de donnÃ©es (le fichier `.db`)
2. **CrÃ©er des copies** avant chaque nouvelle expÃ©rimentation majeure
3. **Exporter vers CSV** pour l'archivage long terme et le partage

```bash
# CrÃ©er une sauvegarde
cp experiment_results/experiment_data.db experiment_results/backup_$(date +%Y%m%d_%H%M%S).db

# Exporter tout vers CSV
sqlite3 experiment_results/experiment_data.db ".mode csv" ".headers on" \
        ".output all_results.csv" "SELECT * FROM results;" ".quit"
```

## Prochaines Ã©tapes

- Bien regarder et travailler sur la doc 
- VÃ©rifier les datas que l'on obtient en sortie 
- Il manque toujours la clÃ© de Bing 
- Faire attention aux crÃ©dits sur les diffÃ©rentes clÃ©s API
- Commencer Ã  faire une premiÃ¨re analyse sur un test

Ensuite on verra pour :

- [ ] SystÃ¨me d'automatisation temporelle (planification des exÃ©cutions)
- [ ] IntÃ©gration Microsoft Copilot
- [ ] AmÃ©lioration du pool de requÃªtes
- [ ] Dashboard de visualisation en temps rÃ©el
